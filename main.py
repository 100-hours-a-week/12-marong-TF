import os
import json
import datetime
import requests
import functions_framework
from datetime import timezone
from google.cloud import bigquery
from google.cloud import monitoring_v3


@functions_framework.http
def send_billing_report(request):
    """ë§¤ì¼ ì•„ì¹¨ GCP ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ Discordë¡œ ì „ì†¡"""

    # Discord Webhook URL (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •)
    DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')
    PROJECT_ID = os.environ.get('GCP_PROJECT_ID')
    BILLING_ACCOUNT_ID = os.environ.get('BILLING_ACCOUNT_ID')

    if not all([DISCORD_WEBHOOK_URL, PROJECT_ID, BILLING_ACCOUNT_ID]):
        return 'Missing required environment variables', 400

    # í˜„ì¬ ë‚ ì§œì™€ ì–´ì œ ë‚ ì§œ ê³„ì‚°
    today = datetime.date.today()
    yesterday = today - datetime.timedelta(days=1)

    try:
        # 1. ì¼ì¼ ë¹„ìš© ë°ì´í„° ì¡°íšŒ
        billing_data = get_daily_cost(PROJECT_ID, BILLING_ACCOUNT_ID, yesterday)

        # 2. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë°ì´í„° ì¡°íšŒ
        resource_usage = get_resource_usage(PROJECT_ID, yesterday)

        # 3. Discord ë©”ì‹œì§€ ìƒì„±
        message = create_discord_message(billing_data, resource_usage, yesterday)

        # 4. Discordë¡œ ì „ì†¡
        send_to_discord(DISCORD_WEBHOOK_URL, message)

        return 'Report sent successfully', 200
    except Exception as e:
        print(f"Error in send_billing_report: {e}")
        return f'Error: {str(e)}', 500


def get_daily_cost(project_id, billing_account_id, date):
    """BigQueryì—ì„œ ì¼ì¼ ë¹„ìš© ì¡°íšŒ"""
    client = bigquery.Client()

    # BigQueryì—ì„œ billing export ë°ì´í„° ì¡°íšŒ
    query = f"""
    SELECT
        service.description as service_name,
        sku.description as sku_description,
        SUM(cost) as total_cost
    FROM `{project_id}.billing_export.gcp_billing_export*`
    WHERE 
        billing_account_id = @billing_account_id
        AND DATE(usage_start_time) = @target_date
    GROUP BY service_name, sku_description
    ORDER BY total_cost DESC
    LIMIT 10
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("billing_account_id", "STRING", billing_account_id),
            bigquery.ScalarQueryParameter("target_date", "DATE", date.strftime("%Y-%m-%d")),
        ]
    )

    try:
        query_job = client.query(query, job_config=job_config)
        results = query_job.result()

        billing_data = []
        total_cost = 0

        for row in results:
            billing_data.append({
                'service': row.service_name,
                'sku': row.sku_description,
                'cost': row.total_cost
            })
            total_cost += row.total_cost

        return {
            'items': billing_data,
            'total_cost': total_cost
        }
    except Exception as e:
        print(f"Error in get_daily_cost: {e}")
        return {
            'items': [],
            'total_cost': 0
        }


def get_resource_usage(project_id, date):
    """Monitoring APIì—ì„œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
    try:
        client = monitoring_v3.MetricServiceClient()
        project_name = f"projects/{project_id}"

        # ì‹œê°„ ê°„ê²© ì„¤ì • (ì–´ì œ í•˜ë£¨)
        interval = monitoring_v3.TimeInterval(
            {
                "end_time": datetime.datetime.combine(date + datetime.timedelta(days=1), datetime.time.min,
                                                      tzinfo=timezone.utc),
                "start_time": datetime.datetime.combine(date, datetime.time.min, tzinfo=timezone.utc),
            }
        )

        # Compute Engine CPU ì‚¬ìš©ë¥  ì¡°íšŒ
        cpu_usage = get_metric_data(client, project_name,
                                    'compute.googleapis.com/instance/cpu/utilization',
                                    interval)

        # Cloud Storage ì‚¬ìš©ëŸ‰ ì¡°íšŒ
        storage_usage = get_metric_data(client, project_name,
                                        'storage.googleapis.com/storage/total_bytes',
                                        interval)

        # Cloud SQL ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°íšŒ
        sql_memory = get_metric_data(client, project_name,
                                     'cloudsql.googleapis.com/database/memory/utilization',
                                     interval)

        return {
            'cpu_usage': cpu_usage,
            'storage_usage': storage_usage,
            'sql_memory': sql_memory
        }
    except Exception as e:
        print(f"Error in get_resource_usage: {e}")
        return {
            'cpu_usage': None,
            'storage_usage': None,
            'sql_memory': None
        }


def get_metric_data(client, project_name, metric_type, interval):
    """íŠ¹ì • ë©”íŠ¸ë¦­ì˜ ë°ì´í„° ì¡°íšŒ"""
    try:
        results = client.list_time_series(
            request={
                "name": project_name,
                "filter": f'metric.type="{metric_type}"',
                "interval": interval,
                "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,
            }
        )

        values = []
        for ts in results:
            for point in ts.points:
                values.append(point.value.double_value or point.value.int64_value)

        if values:
            return {
                'average': sum(values) / len(values),
                'maximum': max(values),
                'minimum': min(values)
            }
        return None
    except Exception as e:
        print(f"Error getting metric {metric_type}: {e}")
        return None


def create_discord_message(billing_data, resource_usage, date):
    """Discord ë©”ì‹œì§€ í˜•ì‹ ìƒì„±"""
    # Embed ë©”ì‹œì§€ ìƒì„±
    embed = {
        "title": f"ğŸ“Š GCP ì¼ì¼ ë¦¬í¬íŠ¸ - {date.strftime('%Y-%m-%d')}",
        "color": 0x4285F4,  # Google Blue
        "fields": [],
        "footer": {
            "text": "GCP ë¹„ìš© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"
        },
        "timestamp": datetime.datetime.now(timezone.utc).isoformat()
    }

    # ì´ ë¹„ìš© ì¶”ê°€
    embed["fields"].append({
        "name": "ğŸ’° ì´ ë¹„ìš©",
        "value": f"${billing_data['total_cost']:.2f} USD",
        "inline": False
    })

    # ìƒìœ„ ë¹„ìš© ì„œë¹„ìŠ¤ ì¶”ê°€
    if billing_data['items']:
        top_costs = "\n".join([
            f"â€¢ {item['service']}: ${item['cost']:.2f}"
            for item in billing_data['items'][:5]
        ])
        embed["fields"].append({
            "name": "ğŸ“‹ ìƒìœ„ ë¹„ìš© ì„œë¹„ìŠ¤",
            "value": top_costs,
            "inline": False
        })

    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ê°€
    if resource_usage['cpu_usage']:
        embed["fields"].append({
            "name": "ğŸ–¥ï¸ CPU ì‚¬ìš©ë¥ ",
            "value": f"í‰ê· : {resource_usage['cpu_usage']['average']:.1f}%\nìµœëŒ€: {resource_usage['cpu_usage']['maximum']:.1f}%",
            "inline": True
        })

    if resource_usage['storage_usage']:
        storage_gb = resource_usage['storage_usage']['average'] / (1024 ** 3)
        embed["fields"].append({
            "name": "ğŸ’¾ Storage ì‚¬ìš©ëŸ‰",
            "value": f"{storage_gb:.2f} GB",
            "inline": True
        })

    if resource_usage['sql_memory']:
        embed["fields"].append({
            "name": "ğŸ—„ï¸ Cloud SQL ë©”ëª¨ë¦¬",
            "value": f"í‰ê· : {resource_usage['sql_memory']['average']:.1f}%",
            "inline": True
        })

    return {"embeds": [embed]}


def send_to_discord(webhook_url, message):
    """Discordë¡œ ë©”ì‹œì§€ ì „ì†¡"""
    headers = {'Content-Type': 'application/json'}
    response = requests.post(webhook_url, json=message, headers=headers)

    if response.status_code != 204:
        raise Exception(f"Discord webhook failed: {response.status_code}, {response.text}")

    return response